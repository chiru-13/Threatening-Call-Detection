{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdY5GG891vW3"
      },
      "outputs": [],
      "source": [
        "#Importing the libraries for conversion of audio to text\n",
        "import speech_recognition as sr\n",
        "import IPython"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize recognizer\n",
        "r = sr.Recognizer()\n",
        "\n",
        "# Capture audio from microphone\n",
        "with sr.Microphone() as source:\n",
        "    print(\"Speak something to record the audio...\")\n",
        "    audio = r.listen(source)\n",
        "\n",
        "# Convert audio to text\n",
        "try:\n",
        "    text = r.recognize_google(audio)\n",
        "    print(\"You said: \" + text)\n",
        "except sr.UnknownValueError:\n",
        "    print(\"Sorry, I could not understand what you said\")\n",
        "except sr.RequestError:\n",
        "    print(\"Sorry, my speech service is currently down\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q29FoX0ue1Jl",
        "outputId": "6a102040-91c9-4934-cc44-335f7ad94603"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speak something to record the audio...\n",
            "You said: I will kill you\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvHUqEFO2O4Y",
        "outputId": "f53d5bc6-354b-44d3-d1ee-c56a02aa70b6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at ./fine-tuned-distilbert-model were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at ./fine-tuned-distilbert-model and are newly initialized: ['dropout_59']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input text: 'I will kill you'\n",
            "Predicted class: Threat\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from transformers import DistilBertTokenizerFast, TFDistilBertForSequenceClassification\n",
        "\n",
        "# Load the saved tokenizer and model\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('./fine-tuned-distilbert-tokenizer')\n",
        "model = TFDistilBertForSequenceClassification.from_pretrained('./fine-tuned-distilbert-model')\n",
        "\n",
        "# Define the input text\n",
        "input_text = text\n",
        "\n",
        "# Tokenize the input text\n",
        "inputs = tokenizer(input_text, return_tensors=\"tf\", truncation=True, padding=True)\n",
        "\n",
        "# Get the predictions\n",
        "outputs = model(inputs)\n",
        "logits = outputs.logits\n",
        "\n",
        "# Convert logits to probabilities\n",
        "probs = tf.nn.softmax(logits, axis=-1)\n",
        "predicted_class = tf.argmax(probs, axis=-1).numpy()[0]\n",
        "\n",
        "# Map predicted class to label\n",
        "class_labels = [\"Non-threat\", \"Threat\"]\n",
        "predicted_label = class_labels[predicted_class]\n",
        "\n",
        "print(f\"Input text: '{input_text}'\")\n",
        "print(f\"Predicted class: {predicted_label}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFbac4eg3-yU"
      },
      "outputs": [],
      "source": [
        "#importing the required libraries to send the messages\n",
        "import pywhatkit\n",
        "import datetime\n",
        "#storing the numbers to which you want to send the alert\n",
        "registernumbers=[\"---numbers to which you want to send the alert---\"]\n",
        "\n",
        "if predicted_label==\"Threat\":\n",
        "    for j in range(0,len(registernumbers)):\n",
        "        number=registernumbers[j]\n",
        "        message = \"Threatening call alert\"\n",
        "        pywhatkit.sendwhatmsg(number, message, datetime.datetime.now().hour, datetime.datetime.now().minute + 1)\n",
        "else:\n",
        "    print(\"it's not a threaten call\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}